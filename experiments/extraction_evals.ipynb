{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74147fc4-ceca-4846-8182-9fea4b15a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db102eda-2cb6-4934-b781-fdc5f21350cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from openai import OpenAI, RateLimitError\n",
    "from tqdm import tqdm\n",
    "\n",
    "# extra deps needed for this beyond ptracker requirements: pip install openpyxl gdown\n",
    "import backoff\n",
    "import gdown\n",
    "import openpyxl\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from ptracker.api.models import Action, Promise\n",
    "from ptracker.core import constants\n",
    "from ptracker.core.llm_utils import cosine_similarity\n",
    "from ptracker.core.sources import ActionExtractor, PromiseExtractor\n",
    "from ptracker.core.sources.source_analyzer import SourceAnalyzer\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2dd928-27b7-4b66-9f21-650323f287fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(analyzer: SourceAnalyzer, candidate_name: str, urls: list[str]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Extract entity jsons *without* inserting them into the database.\n",
    "\n",
    "    :param candidate_name: the name of the candidate.\n",
    "    :param urls: list of source urls from which we want to extract entities\n",
    "    :return: list of entity extracts, such as promise create or action create jsons.\n",
    "    \"\"\"\n",
    "    assert len(analyzer.entity_registry) == 1, f\"This extraction function only operates on one entity type at a time, but {len(analyzer.entity_registry)=} were supplied instead.\"\n",
    "    entity_type = next(iter(analyzer.entity_registry))\n",
    "    entity_jsons = analyzer.construct_entity_jsons(candidate_name=candidate_name, urls=urls).get(entity_type, {})\n",
    "    deduplicator = analyzer.entity_registry[entity_type]\n",
    "    return deduplicator.deduplicate_entities(entity_jsons=entity_jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74122e73-100b-4218-a070-812f79383db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_extracted_entities(extracts: list[dict], ground_truths: list[list[float]]) -> tuple[float]:\n",
    "    \"\"\"\n",
    "    Given extracted entities and embeddings for the ground truth datasets, calculate eval stats.\n",
    "\n",
    "    :param extracts: entity creation jsons, like for promises or actions.\n",
    "    :param ground_truths: ground truth embeddings.\n",
    "    :return: tuple of stats (recall, precision)\n",
    "    \"\"\"\n",
    "    print(len(extracts))\n",
    "    print(len(ground_truths))\n",
    "    N = len(ground_truths)\n",
    "    matches = 0\n",
    "    counts = {idx: 0 for idx in range(len(ground_truths))}\n",
    "    for extract in extracts:\n",
    "        is_match = False\n",
    "        for idx, reference in enumerate(ground_truths):\n",
    "            if cosine_similarity(extract['embedding'], reference) >= constants.DUPLICATE_ENTITY_SIM_THRESHOLD:\n",
    "                is_match = True\n",
    "                counts[idx] += 1\n",
    "        matches += int(is_match)\n",
    "\n",
    "    recall = sum([(v > 0) for v in counts.values()]) / N\n",
    "    precision = matches / len(extracts)\n",
    "\n",
    "    print(f\"Recall on reference set: {recall}\")\n",
    "    print(f\"Match precision: {precision}\")\n",
    "\n",
    "    return recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f58cf7-3bd5-438c-b053-39b22e30689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo, RateLimitError)\n",
    "def get_embedding(text: str):\n",
    "    return client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-large\",\n",
    "        encoding_format=\"float\",\n",
    "        dimensions=256,\n",
    "    ).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f05823-1404-4e73-9de2-3245088710f8",
   "metadata": {},
   "source": [
    "# Promise Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866121a1-a006-4ade-b9d2-5921b72281c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(delete=False, dir=os.getcwd(), suffix=\".xlsx\") as fp:\n",
    "    gdown.download(id=\"1s08EzhkD5KaWuZaLTuS6KquVYniheulkIBgtPdMUZbU\", output=fp.name)\n",
    "    # df = pd.read_excel(fp.name, sheet_name=None)\n",
    "    wb = openpyxl.load_workbook(fp.name)\n",
    "os.unlink(fp.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d4faf-e9ec-4c2e-a0f6-160b150ae1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets = wb.sheetnames\n",
    "promise_data = []\n",
    "for sheet in sheets:\n",
    "    name = ' '.join(sheet.strip().split()[:2])\n",
    "    for row in wb[sheet].iter_rows(min_row=2):\n",
    "        link_obj = row[0].hyperlink\n",
    "        if link_obj is not None:\n",
    "            promise_data.append((name, link_obj.target, row[1].value))\n",
    "        else:\n",
    "            # We ran out of rows; no more sources. Assumes data is one contiguous section.\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab7c0b-5de1-43eb-8190-3554ed3c7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor() as executor:\n",
    "    ref_embeddings = list(tqdm(executor.map(lambda tup: get_embedding(tup[2]), promise_data), position=0, leave=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738a904-11f0-416e-91d1-df9fe8a13964",
   "metadata": {},
   "outputs": [],
   "source": [
    "promise_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf0d06-ed12-4630-b213-d62e7e55bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_mapping = {}\n",
    "for cname, url, _ in promise_data:\n",
    "    if cname not in article_mapping:\n",
    "        article_mapping[cname] = set()\n",
    "    article_mapping[cname].add(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de80d92-f60d-4da3-a3b2-7df4f93c32a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyzer = SourceAnalyzer()\n",
    "analyzer.register_entity(entity=Promise, extractor=PromiseExtractor)\n",
    "\n",
    "all_entities = []\n",
    "for idx, cname in enumerate(article_mapping):\n",
    "    cand_predicted_entities = extract_entities(analyzer, cname, list(article_mapping[cname]))\n",
    "    all_entities.extend(cand_predicted_entities)\n",
    "evaluate_extracted_entities(cand_predicted_entities, ref_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb50fa3-c8f1-4442-ba00-7df4869aaa71",
   "metadata": {},
   "source": [
    "# Action Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0103e6-79a6-4e4e-9ada-8aa99c3820b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO once we have ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fa4e2-664f-415b-bc19-5830a83c3d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
